{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f436d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargado ls1.parquet -> variable: df_ls1 | shape=(1058, 4)\n",
      "Cargado ls2.parquet -> variable: df_ls2 | shape=(902, 4)\n",
      "Cargado ls3.parquet -> variable: df_ls3 | shape=(1056, 4)\n",
      "Cargado ls4.parquet -> variable: df_ls4 | shape=(1056, 4)\n",
      "Cargado ls5.parquet -> variable: df_ls5 | shape=(1058, 4)\n",
      "Cargado ls6.parquet -> variable: df_ls6 | shape=(15, 4)\n",
      "\n",
      "=== EDA: ls1 ===\n",
      "Duplicados (filas completas): 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alvar\\AppData\\Local\\Temp\\ipykernel_18932\\4271467526.py:70: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  s = pd.to_datetime(series, errors=\"coerce\", utc=False, infer_datetime_format=True)\n",
      "C:\\Users\\alvar\\AppData\\Local\\Temp\\ipykernel_18932\\4271467526.py:70: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  s = pd.to_datetime(series, errors=\"coerce\", utc=False, infer_datetime_format=True)\n",
      "C:\\Users\\alvar\\AppData\\Local\\Temp\\ipykernel_18932\\4271467526.py:70: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  s = pd.to_datetime(series, errors=\"coerce\", utc=False, infer_datetime_format=True)\n",
      "C:\\Users\\alvar\\AppData\\Local\\Temp\\ipykernel_18932\\4271467526.py:70: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  s = pd.to_datetime(series, errors=\"coerce\", utc=False, infer_datetime_format=True)\n",
      "C:\\Users\\alvar\\AppData\\Local\\Temp\\ipykernel_18932\\4271467526.py:70: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  s = pd.to_datetime(series, errors=\"coerce\", utc=False, infer_datetime_format=True)\n",
      "C:\\Users\\alvar\\AppData\\Local\\Temp\\ipykernel_18932\\4271467526.py:70: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  s = pd.to_datetime(series, errors=\"coerce\", utc=False, infer_datetime_format=True)\n",
      "C:\\Users\\alvar\\AppData\\Local\\Temp\\ipykernel_18932\\4271467526.py:70: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  s = pd.to_datetime(series, errors=\"coerce\", utc=False, infer_datetime_format=True)\n",
      "C:\\Users\\alvar\\AppData\\Local\\Temp\\ipykernel_18932\\4271467526.py:70: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  s = pd.to_datetime(series, errors=\"coerce\", utc=False, infer_datetime_format=True)\n",
      "C:\\Users\\alvar\\AppData\\Local\\Temp\\ipykernel_18932\\4271467526.py:70: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  s = pd.to_datetime(series, errors=\"coerce\", utc=False, infer_datetime_format=True)\n",
      "C:\\Users\\alvar\\AppData\\Local\\Temp\\ipykernel_18932\\4271467526.py:70: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  s = pd.to_datetime(series, errors=\"coerce\", utc=False, infer_datetime_format=True)\n",
      "C:\\Users\\alvar\\AppData\\Local\\Temp\\ipykernel_18932\\4271467526.py:70: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  s = pd.to_datetime(series, errors=\"coerce\", utc=False, infer_datetime_format=True)\n",
      "C:\\Users\\alvar\\AppData\\Local\\Temp\\ipykernel_18932\\4271467526.py:70: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  s = pd.to_datetime(series, errors=\"coerce\", utc=False, infer_datetime_format=True)\n",
      "C:\\Users\\alvar\\AppData\\Local\\Temp\\ipykernel_18932\\4271467526.py:70: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  s = pd.to_datetime(series, errors=\"coerce\", utc=False, infer_datetime_format=True)\n",
      "C:\\Users\\alvar\\AppData\\Local\\Temp\\ipykernel_18932\\4271467526.py:70: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  s = pd.to_datetime(series, errors=\"coerce\", utc=False, infer_datetime_format=True)\n",
      "C:\\Users\\alvar\\AppData\\Local\\Temp\\ipykernel_18932\\4271467526.py:70: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  s = pd.to_datetime(series, errors=\"coerce\", utc=False, infer_datetime_format=True)\n",
      "C:\\Users\\alvar\\AppData\\Local\\Temp\\ipykernel_18932\\4271467526.py:70: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  s = pd.to_datetime(series, errors=\"coerce\", utc=False, infer_datetime_format=True)\n",
      "C:\\Users\\alvar\\AppData\\Local\\Temp\\ipykernel_18932\\4271467526.py:70: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  s = pd.to_datetime(series, errors=\"coerce\", utc=False, infer_datetime_format=True)\n",
      "C:\\Users\\alvar\\AppData\\Local\\Temp\\ipykernel_18932\\4271467526.py:70: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  s = pd.to_datetime(series, errors=\"coerce\", utc=False, infer_datetime_format=True)\n",
      "C:\\Users\\alvar\\AppData\\Local\\Temp\\ipykernel_18932\\4271467526.py:70: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  s = pd.to_datetime(series, errors=\"coerce\", utc=False, infer_datetime_format=True)\n",
      "C:\\Users\\alvar\\AppData\\Local\\Temp\\ipykernel_18932\\4271467526.py:70: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  s = pd.to_datetime(series, errors=\"coerce\", utc=False, infer_datetime_format=True)\n",
      "C:\\Users\\alvar\\AppData\\Local\\Temp\\ipykernel_18932\\4271467526.py:70: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  s = pd.to_datetime(series, errors=\"coerce\", utc=False, infer_datetime_format=True)\n",
      "C:\\Users\\alvar\\AppData\\Local\\Temp\\ipykernel_18932\\4271467526.py:70: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  s = pd.to_datetime(series, errors=\"coerce\", utc=False, infer_datetime_format=True)\n",
      "C:\\Users\\alvar\\AppData\\Local\\Temp\\ipykernel_18932\\4271467526.py:70: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  s = pd.to_datetime(series, errors=\"coerce\", utc=False, infer_datetime_format=True)\n",
      "C:\\Users\\alvar\\AppData\\Local\\Temp\\ipykernel_18932\\4271467526.py:70: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  s = pd.to_datetime(series, errors=\"coerce\", utc=False, infer_datetime_format=True)\n",
      "C:\\Users\\alvar\\AppData\\Local\\Temp\\ipykernel_18932\\4271467526.py:70: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  s = pd.to_datetime(series, errors=\"coerce\", utc=False, infer_datetime_format=True)\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "mac",
         "rawType": "string",
         "type": "string"
        },
        {
         "name": "time",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "vlx",
         "rawType": "Float64",
         "type": "float"
        },
        {
         "name": "source_file",
         "rawType": "string",
         "type": "string"
        }
       ],
       "ref": "b61b79cc-3d84-4d62-a194-fd5e26e8fe21",
       "rows": [
        [
         "0",
         "40:22:D8:F1:E3:70",
         "2025-07-15 12:14:21",
         "317.0",
         "data_drive\\LS1\\silos_vlx_1.csv"
        ],
        [
         "1",
         "40:22:D8:F1:E3:70",
         "2025-07-15 12:44:22",
         "326.0",
         "data_drive\\LS1\\silos_vlx_1.csv"
        ],
        [
         "2",
         "40:22:D8:F1:E3:70",
         "2025-07-15 13:14:24",
         "315.0",
         "data_drive\\LS1\\silos_vlx_1.csv"
        ],
        [
         "3",
         "40:22:D8:F1:E3:70",
         "2025-07-15 13:44:26",
         "316.0",
         "data_drive\\LS1\\silos_vlx_1.csv"
        ],
        [
         "4",
         "40:22:D8:F1:E3:70",
         "2025-07-15 14:14:27",
         "308.0",
         "data_drive\\LS1\\silos_vlx_1.csv"
        ],
        [
         "5",
         "40:22:D8:F1:E3:70",
         "2025-07-15 14:44:29",
         "309.0",
         "data_drive\\LS1\\silos_vlx_1.csv"
        ],
        [
         "6",
         "40:22:D8:F1:E3:70",
         "2025-07-15 15:14:30",
         "309.0",
         "data_drive\\LS1\\silos_vlx_1.csv"
        ],
        [
         "7",
         "40:22:D8:F1:E3:70",
         "2025-07-15 15:44:32",
         "310.0",
         "data_drive\\LS1\\silos_vlx_1.csv"
        ],
        [
         "8",
         "40:22:D8:F1:E3:70",
         "2025-07-15 16:14:33",
         "316.0",
         "data_drive\\LS1\\silos_vlx_1.csv"
        ],
        [
         "9",
         "40:22:D8:F1:E3:70",
         "2025-07-15 16:44:35",
         "316.0",
         "data_drive\\LS1\\silos_vlx_1.csv"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mac</th>\n",
       "      <th>time</th>\n",
       "      <th>vlx</th>\n",
       "      <th>source_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40:22:D8:F1:E3:70</td>\n",
       "      <td>2025-07-15 12:14:21</td>\n",
       "      <td>317.0</td>\n",
       "      <td>data_drive\\LS1\\silos_vlx_1.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40:22:D8:F1:E3:70</td>\n",
       "      <td>2025-07-15 12:44:22</td>\n",
       "      <td>326.0</td>\n",
       "      <td>data_drive\\LS1\\silos_vlx_1.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40:22:D8:F1:E3:70</td>\n",
       "      <td>2025-07-15 13:14:24</td>\n",
       "      <td>315.0</td>\n",
       "      <td>data_drive\\LS1\\silos_vlx_1.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40:22:D8:F1:E3:70</td>\n",
       "      <td>2025-07-15 13:44:26</td>\n",
       "      <td>316.0</td>\n",
       "      <td>data_drive\\LS1\\silos_vlx_1.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40:22:D8:F1:E3:70</td>\n",
       "      <td>2025-07-15 14:14:27</td>\n",
       "      <td>308.0</td>\n",
       "      <td>data_drive\\LS1\\silos_vlx_1.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>40:22:D8:F1:E3:70</td>\n",
       "      <td>2025-07-15 14:44:29</td>\n",
       "      <td>309.0</td>\n",
       "      <td>data_drive\\LS1\\silos_vlx_1.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>40:22:D8:F1:E3:70</td>\n",
       "      <td>2025-07-15 15:14:30</td>\n",
       "      <td>309.0</td>\n",
       "      <td>data_drive\\LS1\\silos_vlx_1.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>40:22:D8:F1:E3:70</td>\n",
       "      <td>2025-07-15 15:44:32</td>\n",
       "      <td>310.0</td>\n",
       "      <td>data_drive\\LS1\\silos_vlx_1.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>40:22:D8:F1:E3:70</td>\n",
       "      <td>2025-07-15 16:14:33</td>\n",
       "      <td>316.0</td>\n",
       "      <td>data_drive\\LS1\\silos_vlx_1.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>40:22:D8:F1:E3:70</td>\n",
       "      <td>2025-07-15 16:44:35</td>\n",
       "      <td>316.0</td>\n",
       "      <td>data_drive\\LS1\\silos_vlx_1.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 mac                time    vlx                     source_file\n",
       "0  40:22:D8:F1:E3:70 2025-07-15 12:14:21  317.0  data_drive\\LS1\\silos_vlx_1.csv\n",
       "1  40:22:D8:F1:E3:70 2025-07-15 12:44:22  326.0  data_drive\\LS1\\silos_vlx_1.csv\n",
       "2  40:22:D8:F1:E3:70 2025-07-15 13:14:24  315.0  data_drive\\LS1\\silos_vlx_1.csv\n",
       "3  40:22:D8:F1:E3:70 2025-07-15 13:44:26  316.0  data_drive\\LS1\\silos_vlx_1.csv\n",
       "4  40:22:D8:F1:E3:70 2025-07-15 14:14:27  308.0  data_drive\\LS1\\silos_vlx_1.csv\n",
       "5  40:22:D8:F1:E3:70 2025-07-15 14:44:29  309.0  data_drive\\LS1\\silos_vlx_1.csv\n",
       "6  40:22:D8:F1:E3:70 2025-07-15 15:14:30  309.0  data_drive\\LS1\\silos_vlx_1.csv\n",
       "7  40:22:D8:F1:E3:70 2025-07-15 15:44:32  310.0  data_drive\\LS1\\silos_vlx_1.csv\n",
       "8  40:22:D8:F1:E3:70 2025-07-15 16:14:33  316.0  data_drive\\LS1\\silos_vlx_1.csv\n",
       "9  40:22:D8:F1:E3:70 2025-07-15 16:44:35  316.0  data_drive\\LS1\\silos_vlx_1.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "➡ Informe Markdown: D:\\ls_feed\\data_drive\\_eda\\ls1\\report.md\n",
      "\n",
      "=== EDA: ls2 ===\n",
      "Duplicados (filas completas): 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "mac",
         "rawType": "string",
         "type": "string"
        },
        {
         "name": "time",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "vlx",
         "rawType": "Float64",
         "type": "float"
        },
        {
         "name": "source_file",
         "rawType": "string",
         "type": "string"
        }
       ],
       "ref": "05d8ef1f-ccf2-4e96-a1a9-ea0c90302fe7",
       "rows": [
        [
         "0",
         "40:22:D8:F1:E2:CC",
         "2025-07-15 12:14:48",
         "283.0",
         "data_drive\\LS2\\silos_vlx_0.csv"
        ],
        [
         "1",
         "40:22:D8:F1:E2:CC",
         "2025-07-15 12:44:49",
         "283.0",
         "data_drive\\LS2\\silos_vlx_0.csv"
        ],
        [
         "2",
         "40:22:D8:F1:E2:CC",
         "2025-07-15 13:14:51",
         "281.0",
         "data_drive\\LS2\\silos_vlx_0.csv"
        ],
        [
         "3",
         "40:22:D8:F1:E2:CC",
         "2025-07-15 13:44:53",
         "278.0",
         "data_drive\\LS2\\silos_vlx_0.csv"
        ],
        [
         "4",
         "40:22:D8:F1:E2:CC",
         "2025-07-15 14:14:54",
         "279.0",
         "data_drive\\LS2\\silos_vlx_0.csv"
        ],
        [
         "5",
         "40:22:D8:F1:E2:CC",
         "2025-07-15 14:44:56",
         "285.0",
         "data_drive\\LS2\\silos_vlx_0.csv"
        ],
        [
         "6",
         "40:22:D8:F1:E2:CC",
         "2025-07-15 15:14:57",
         "281.0",
         "data_drive\\LS2\\silos_vlx_0.csv"
        ],
        [
         "7",
         "40:22:D8:F1:E2:CC",
         "2025-07-15 15:44:59",
         "277.0",
         "data_drive\\LS2\\silos_vlx_0.csv"
        ],
        [
         "8",
         "40:22:D8:F1:E2:CC",
         "2025-07-15 16:15:00",
         "276.0",
         "data_drive\\LS2\\silos_vlx_0.csv"
        ],
        [
         "9",
         "40:22:D8:F1:E2:CC",
         "2025-07-15 16:45:02",
         "279.0",
         "data_drive\\LS2\\silos_vlx_0.csv"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mac</th>\n",
       "      <th>time</th>\n",
       "      <th>vlx</th>\n",
       "      <th>source_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40:22:D8:F1:E2:CC</td>\n",
       "      <td>2025-07-15 12:14:48</td>\n",
       "      <td>283.0</td>\n",
       "      <td>data_drive\\LS2\\silos_vlx_0.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40:22:D8:F1:E2:CC</td>\n",
       "      <td>2025-07-15 12:44:49</td>\n",
       "      <td>283.0</td>\n",
       "      <td>data_drive\\LS2\\silos_vlx_0.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40:22:D8:F1:E2:CC</td>\n",
       "      <td>2025-07-15 13:14:51</td>\n",
       "      <td>281.0</td>\n",
       "      <td>data_drive\\LS2\\silos_vlx_0.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40:22:D8:F1:E2:CC</td>\n",
       "      <td>2025-07-15 13:44:53</td>\n",
       "      <td>278.0</td>\n",
       "      <td>data_drive\\LS2\\silos_vlx_0.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40:22:D8:F1:E2:CC</td>\n",
       "      <td>2025-07-15 14:14:54</td>\n",
       "      <td>279.0</td>\n",
       "      <td>data_drive\\LS2\\silos_vlx_0.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>40:22:D8:F1:E2:CC</td>\n",
       "      <td>2025-07-15 14:44:56</td>\n",
       "      <td>285.0</td>\n",
       "      <td>data_drive\\LS2\\silos_vlx_0.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>40:22:D8:F1:E2:CC</td>\n",
       "      <td>2025-07-15 15:14:57</td>\n",
       "      <td>281.0</td>\n",
       "      <td>data_drive\\LS2\\silos_vlx_0.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>40:22:D8:F1:E2:CC</td>\n",
       "      <td>2025-07-15 15:44:59</td>\n",
       "      <td>277.0</td>\n",
       "      <td>data_drive\\LS2\\silos_vlx_0.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>40:22:D8:F1:E2:CC</td>\n",
       "      <td>2025-07-15 16:15:00</td>\n",
       "      <td>276.0</td>\n",
       "      <td>data_drive\\LS2\\silos_vlx_0.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>40:22:D8:F1:E2:CC</td>\n",
       "      <td>2025-07-15 16:45:02</td>\n",
       "      <td>279.0</td>\n",
       "      <td>data_drive\\LS2\\silos_vlx_0.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 mac                time    vlx                     source_file\n",
       "0  40:22:D8:F1:E2:CC 2025-07-15 12:14:48  283.0  data_drive\\LS2\\silos_vlx_0.csv\n",
       "1  40:22:D8:F1:E2:CC 2025-07-15 12:44:49  283.0  data_drive\\LS2\\silos_vlx_0.csv\n",
       "2  40:22:D8:F1:E2:CC 2025-07-15 13:14:51  281.0  data_drive\\LS2\\silos_vlx_0.csv\n",
       "3  40:22:D8:F1:E2:CC 2025-07-15 13:44:53  278.0  data_drive\\LS2\\silos_vlx_0.csv\n",
       "4  40:22:D8:F1:E2:CC 2025-07-15 14:14:54  279.0  data_drive\\LS2\\silos_vlx_0.csv\n",
       "5  40:22:D8:F1:E2:CC 2025-07-15 14:44:56  285.0  data_drive\\LS2\\silos_vlx_0.csv\n",
       "6  40:22:D8:F1:E2:CC 2025-07-15 15:14:57  281.0  data_drive\\LS2\\silos_vlx_0.csv\n",
       "7  40:22:D8:F1:E2:CC 2025-07-15 15:44:59  277.0  data_drive\\LS2\\silos_vlx_0.csv\n",
       "8  40:22:D8:F1:E2:CC 2025-07-15 16:15:00  276.0  data_drive\\LS2\\silos_vlx_0.csv\n",
       "9  40:22:D8:F1:E2:CC 2025-07-15 16:45:02  279.0  data_drive\\LS2\\silos_vlx_0.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "➡ Informe Markdown: D:\\ls_feed\\data_drive\\_eda\\ls2\\report.md\n",
      "\n",
      "=== EDA: ls3 ===\n",
      "Duplicados (filas completas): 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "mac",
         "rawType": "string",
         "type": "string"
        },
        {
         "name": "time",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "vlx",
         "rawType": "Float64",
         "type": "float"
        },
        {
         "name": "source_file",
         "rawType": "string",
         "type": "string"
        }
       ],
       "ref": "093cf0d4-1d7f-46a0-b716-4b43bde16a02",
       "rows": [
        [
         "0",
         "40:22:D8:F1:E3:80",
         "2025-07-15 12:37:08",
         "298.0",
         "data_drive\\LS3\\silos_vlx_0.csv"
        ],
        [
         "1",
         "40:22:D8:F1:E3:80",
         "2025-07-15 13:07:10",
         "296.0",
         "data_drive\\LS3\\silos_vlx_0.csv"
        ],
        [
         "2",
         "40:22:D8:F1:E3:80",
         "2025-07-15 13:37:11",
         "297.0",
         "data_drive\\LS3\\silos_vlx_0.csv"
        ],
        [
         "3",
         "40:22:D8:F1:E3:80",
         "2025-07-15 14:07:13",
         "303.0",
         "data_drive\\LS3\\silos_vlx_0.csv"
        ],
        [
         "4",
         "40:22:D8:F1:E3:80",
         "2025-07-15 14:37:14",
         "296.0",
         "data_drive\\LS3\\silos_vlx_0.csv"
        ],
        [
         "5",
         "40:22:D8:F1:E3:80",
         "2025-07-15 15:07:16",
         "296.0",
         "data_drive\\LS3\\silos_vlx_0.csv"
        ],
        [
         "6",
         "40:22:D8:F1:E3:80",
         "2025-07-15 15:37:17",
         "294.0",
         "data_drive\\LS3\\silos_vlx_0.csv"
        ],
        [
         "7",
         "40:22:D8:F1:E3:80",
         "2025-07-15 16:07:19",
         "292.0",
         "data_drive\\LS3\\silos_vlx_0.csv"
        ],
        [
         "8",
         "40:22:D8:F1:E3:80",
         "2025-07-15 16:37:20",
         "286.0",
         "data_drive\\LS3\\silos_vlx_0.csv"
        ],
        [
         "9",
         "40:22:D8:F1:E3:80",
         "2025-07-15 17:07:22",
         "292.0",
         "data_drive\\LS3\\silos_vlx_0.csv"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mac</th>\n",
       "      <th>time</th>\n",
       "      <th>vlx</th>\n",
       "      <th>source_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40:22:D8:F1:E3:80</td>\n",
       "      <td>2025-07-15 12:37:08</td>\n",
       "      <td>298.0</td>\n",
       "      <td>data_drive\\LS3\\silos_vlx_0.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40:22:D8:F1:E3:80</td>\n",
       "      <td>2025-07-15 13:07:10</td>\n",
       "      <td>296.0</td>\n",
       "      <td>data_drive\\LS3\\silos_vlx_0.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40:22:D8:F1:E3:80</td>\n",
       "      <td>2025-07-15 13:37:11</td>\n",
       "      <td>297.0</td>\n",
       "      <td>data_drive\\LS3\\silos_vlx_0.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40:22:D8:F1:E3:80</td>\n",
       "      <td>2025-07-15 14:07:13</td>\n",
       "      <td>303.0</td>\n",
       "      <td>data_drive\\LS3\\silos_vlx_0.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40:22:D8:F1:E3:80</td>\n",
       "      <td>2025-07-15 14:37:14</td>\n",
       "      <td>296.0</td>\n",
       "      <td>data_drive\\LS3\\silos_vlx_0.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>40:22:D8:F1:E3:80</td>\n",
       "      <td>2025-07-15 15:07:16</td>\n",
       "      <td>296.0</td>\n",
       "      <td>data_drive\\LS3\\silos_vlx_0.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>40:22:D8:F1:E3:80</td>\n",
       "      <td>2025-07-15 15:37:17</td>\n",
       "      <td>294.0</td>\n",
       "      <td>data_drive\\LS3\\silos_vlx_0.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>40:22:D8:F1:E3:80</td>\n",
       "      <td>2025-07-15 16:07:19</td>\n",
       "      <td>292.0</td>\n",
       "      <td>data_drive\\LS3\\silos_vlx_0.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>40:22:D8:F1:E3:80</td>\n",
       "      <td>2025-07-15 16:37:20</td>\n",
       "      <td>286.0</td>\n",
       "      <td>data_drive\\LS3\\silos_vlx_0.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>40:22:D8:F1:E3:80</td>\n",
       "      <td>2025-07-15 17:07:22</td>\n",
       "      <td>292.0</td>\n",
       "      <td>data_drive\\LS3\\silos_vlx_0.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 mac                time    vlx                     source_file\n",
       "0  40:22:D8:F1:E3:80 2025-07-15 12:37:08  298.0  data_drive\\LS3\\silos_vlx_0.csv\n",
       "1  40:22:D8:F1:E3:80 2025-07-15 13:07:10  296.0  data_drive\\LS3\\silos_vlx_0.csv\n",
       "2  40:22:D8:F1:E3:80 2025-07-15 13:37:11  297.0  data_drive\\LS3\\silos_vlx_0.csv\n",
       "3  40:22:D8:F1:E3:80 2025-07-15 14:07:13  303.0  data_drive\\LS3\\silos_vlx_0.csv\n",
       "4  40:22:D8:F1:E3:80 2025-07-15 14:37:14  296.0  data_drive\\LS3\\silos_vlx_0.csv\n",
       "5  40:22:D8:F1:E3:80 2025-07-15 15:07:16  296.0  data_drive\\LS3\\silos_vlx_0.csv\n",
       "6  40:22:D8:F1:E3:80 2025-07-15 15:37:17  294.0  data_drive\\LS3\\silos_vlx_0.csv\n",
       "7  40:22:D8:F1:E3:80 2025-07-15 16:07:19  292.0  data_drive\\LS3\\silos_vlx_0.csv\n",
       "8  40:22:D8:F1:E3:80 2025-07-15 16:37:20  286.0  data_drive\\LS3\\silos_vlx_0.csv\n",
       "9  40:22:D8:F1:E3:80 2025-07-15 17:07:22  292.0  data_drive\\LS3\\silos_vlx_0.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "➡ Informe Markdown: D:\\ls_feed\\data_drive\\_eda\\ls3\\report.md\n",
      "\n",
      "=== EDA: ls4 ===\n",
      "Duplicados (filas completas): 71\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "mac",
         "rawType": "string",
         "type": "string"
        },
        {
         "name": "time",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "vlx",
         "rawType": "Float64",
         "type": "float"
        },
        {
         "name": "source_file",
         "rawType": "string",
         "type": "string"
        }
       ],
       "ref": "de1029dd-bca5-450e-b958-6267645d1281",
       "rows": [
        [
         "0",
         "B8:D6:1A:60:95:30",
         "2024-06-14 00:01:02",
         "349.0",
         "data_drive\\LS4\\silos_vlx_0.csv"
        ],
        [
         "1",
         "B8:D6:1A:60:95:30",
         "2024-06-14 00:01:00",
         "352.0",
         "data_drive\\LS4\\silos_vlx_0.csv"
        ],
        [
         "2",
         "B8:D6:1A:60:95:30",
         "2024-06-14 00:01:01",
         "354.0",
         "data_drive\\LS4\\silos_vlx_0.csv"
        ],
        [
         "3",
         "B8:D6:1A:60:95:30",
         "2024-06-14 00:01:03",
         "344.0",
         "data_drive\\LS4\\silos_vlx_0.csv"
        ],
        [
         "4",
         "B8:D6:1A:60:95:30",
         "2024-06-14 00:01:00",
         "342.0",
         "data_drive\\LS4\\silos_vlx_0.csv"
        ],
        [
         "5",
         "B8:D6:1A:60:95:30",
         "2024-06-14 00:01:00",
         "346.0",
         "data_drive\\LS4\\silos_vlx_0.csv"
        ],
        [
         "6",
         "B8:D6:1A:60:95:30",
         "2024-06-14 00:01:01",
         "346.0",
         "data_drive\\LS4\\silos_vlx_0.csv"
        ],
        [
         "7",
         "B8:D6:1A:60:95:30",
         "2024-06-14 00:01:03",
         "349.0",
         "data_drive\\LS4\\silos_vlx_0.csv"
        ],
        [
         "8",
         "B8:D6:1A:60:95:30",
         "2024-06-14 00:01:00",
         "345.0",
         "data_drive\\LS4\\silos_vlx_0.csv"
        ],
        [
         "9",
         "B8:D6:1A:60:95:30",
         "2024-06-14 00:01:02",
         "342.0",
         "data_drive\\LS4\\silos_vlx_0.csv"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mac</th>\n",
       "      <th>time</th>\n",
       "      <th>vlx</th>\n",
       "      <th>source_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B8:D6:1A:60:95:30</td>\n",
       "      <td>2024-06-14 00:01:02</td>\n",
       "      <td>349.0</td>\n",
       "      <td>data_drive\\LS4\\silos_vlx_0.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B8:D6:1A:60:95:30</td>\n",
       "      <td>2024-06-14 00:01:00</td>\n",
       "      <td>352.0</td>\n",
       "      <td>data_drive\\LS4\\silos_vlx_0.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B8:D6:1A:60:95:30</td>\n",
       "      <td>2024-06-14 00:01:01</td>\n",
       "      <td>354.0</td>\n",
       "      <td>data_drive\\LS4\\silos_vlx_0.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B8:D6:1A:60:95:30</td>\n",
       "      <td>2024-06-14 00:01:03</td>\n",
       "      <td>344.0</td>\n",
       "      <td>data_drive\\LS4\\silos_vlx_0.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B8:D6:1A:60:95:30</td>\n",
       "      <td>2024-06-14 00:01:00</td>\n",
       "      <td>342.0</td>\n",
       "      <td>data_drive\\LS4\\silos_vlx_0.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>B8:D6:1A:60:95:30</td>\n",
       "      <td>2024-06-14 00:01:00</td>\n",
       "      <td>346.0</td>\n",
       "      <td>data_drive\\LS4\\silos_vlx_0.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>B8:D6:1A:60:95:30</td>\n",
       "      <td>2024-06-14 00:01:01</td>\n",
       "      <td>346.0</td>\n",
       "      <td>data_drive\\LS4\\silos_vlx_0.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>B8:D6:1A:60:95:30</td>\n",
       "      <td>2024-06-14 00:01:03</td>\n",
       "      <td>349.0</td>\n",
       "      <td>data_drive\\LS4\\silos_vlx_0.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>B8:D6:1A:60:95:30</td>\n",
       "      <td>2024-06-14 00:01:00</td>\n",
       "      <td>345.0</td>\n",
       "      <td>data_drive\\LS4\\silos_vlx_0.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>B8:D6:1A:60:95:30</td>\n",
       "      <td>2024-06-14 00:01:02</td>\n",
       "      <td>342.0</td>\n",
       "      <td>data_drive\\LS4\\silos_vlx_0.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 mac                time    vlx                     source_file\n",
       "0  B8:D6:1A:60:95:30 2024-06-14 00:01:02  349.0  data_drive\\LS4\\silos_vlx_0.csv\n",
       "1  B8:D6:1A:60:95:30 2024-06-14 00:01:00  352.0  data_drive\\LS4\\silos_vlx_0.csv\n",
       "2  B8:D6:1A:60:95:30 2024-06-14 00:01:01  354.0  data_drive\\LS4\\silos_vlx_0.csv\n",
       "3  B8:D6:1A:60:95:30 2024-06-14 00:01:03  344.0  data_drive\\LS4\\silos_vlx_0.csv\n",
       "4  B8:D6:1A:60:95:30 2024-06-14 00:01:00  342.0  data_drive\\LS4\\silos_vlx_0.csv\n",
       "5  B8:D6:1A:60:95:30 2024-06-14 00:01:00  346.0  data_drive\\LS4\\silos_vlx_0.csv\n",
       "6  B8:D6:1A:60:95:30 2024-06-14 00:01:01  346.0  data_drive\\LS4\\silos_vlx_0.csv\n",
       "7  B8:D6:1A:60:95:30 2024-06-14 00:01:03  349.0  data_drive\\LS4\\silos_vlx_0.csv\n",
       "8  B8:D6:1A:60:95:30 2024-06-14 00:01:00  345.0  data_drive\\LS4\\silos_vlx_0.csv\n",
       "9  B8:D6:1A:60:95:30 2024-06-14 00:01:02  342.0  data_drive\\LS4\\silos_vlx_0.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "➡ Informe Markdown: D:\\ls_feed\\data_drive\\_eda\\ls4\\report.md\n",
      "\n",
      "=== EDA: ls5 ===\n",
      "Duplicados (filas completas): 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "mac",
         "rawType": "string",
         "type": "string"
        },
        {
         "name": "time",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "vlx",
         "rawType": "Float64",
         "type": "float"
        },
        {
         "name": "source_file",
         "rawType": "string",
         "type": "string"
        }
       ],
       "ref": "8524d6c9-e882-41d2-8e86-c5f6895d839c",
       "rows": [
        [
         "0",
         "B8:D6:1A:60:94:1C",
         "2025-07-15 11:47:13",
         "330.0",
         "data_drive\\LS5\\silos_vlx_0.csv"
        ],
        [
         "1",
         "B8:D6:1A:60:94:1C",
         "2025-07-15 12:17:15",
         "333.0",
         "data_drive\\LS5\\silos_vlx_0.csv"
        ],
        [
         "2",
         "B8:D6:1A:60:94:1C",
         "2025-07-15 12:47:17",
         "339.0",
         "data_drive\\LS5\\silos_vlx_0.csv"
        ],
        [
         "3",
         "B8:D6:1A:60:94:1C",
         "2025-07-15 13:17:18",
         "338.0",
         "data_drive\\LS5\\silos_vlx_0.csv"
        ],
        [
         "4",
         "B8:D6:1A:60:94:1C",
         "2025-07-15 13:47:20",
         "342.0",
         "data_drive\\LS5\\silos_vlx_0.csv"
        ],
        [
         "5",
         "B8:D6:1A:60:94:1C",
         "2025-07-15 14:17:21",
         "335.0",
         "data_drive\\LS5\\silos_vlx_0.csv"
        ],
        [
         "6",
         "B8:D6:1A:60:94:1C",
         "2025-07-15 14:47:23",
         "335.0",
         "data_drive\\LS5\\silos_vlx_0.csv"
        ],
        [
         "7",
         "B8:D6:1A:60:94:1C",
         "2025-07-15 15:17:24",
         "334.0",
         "data_drive\\LS5\\silos_vlx_0.csv"
        ],
        [
         "8",
         "B8:D6:1A:60:94:1C",
         "2025-07-15 15:47:26",
         "331.0",
         "data_drive\\LS5\\silos_vlx_0.csv"
        ],
        [
         "9",
         "B8:D6:1A:60:94:1C",
         "2025-07-15 16:17:27",
         "335.0",
         "data_drive\\LS5\\silos_vlx_0.csv"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mac</th>\n",
       "      <th>time</th>\n",
       "      <th>vlx</th>\n",
       "      <th>source_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B8:D6:1A:60:94:1C</td>\n",
       "      <td>2025-07-15 11:47:13</td>\n",
       "      <td>330.0</td>\n",
       "      <td>data_drive\\LS5\\silos_vlx_0.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B8:D6:1A:60:94:1C</td>\n",
       "      <td>2025-07-15 12:17:15</td>\n",
       "      <td>333.0</td>\n",
       "      <td>data_drive\\LS5\\silos_vlx_0.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B8:D6:1A:60:94:1C</td>\n",
       "      <td>2025-07-15 12:47:17</td>\n",
       "      <td>339.0</td>\n",
       "      <td>data_drive\\LS5\\silos_vlx_0.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B8:D6:1A:60:94:1C</td>\n",
       "      <td>2025-07-15 13:17:18</td>\n",
       "      <td>338.0</td>\n",
       "      <td>data_drive\\LS5\\silos_vlx_0.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B8:D6:1A:60:94:1C</td>\n",
       "      <td>2025-07-15 13:47:20</td>\n",
       "      <td>342.0</td>\n",
       "      <td>data_drive\\LS5\\silos_vlx_0.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>B8:D6:1A:60:94:1C</td>\n",
       "      <td>2025-07-15 14:17:21</td>\n",
       "      <td>335.0</td>\n",
       "      <td>data_drive\\LS5\\silos_vlx_0.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>B8:D6:1A:60:94:1C</td>\n",
       "      <td>2025-07-15 14:47:23</td>\n",
       "      <td>335.0</td>\n",
       "      <td>data_drive\\LS5\\silos_vlx_0.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>B8:D6:1A:60:94:1C</td>\n",
       "      <td>2025-07-15 15:17:24</td>\n",
       "      <td>334.0</td>\n",
       "      <td>data_drive\\LS5\\silos_vlx_0.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>B8:D6:1A:60:94:1C</td>\n",
       "      <td>2025-07-15 15:47:26</td>\n",
       "      <td>331.0</td>\n",
       "      <td>data_drive\\LS5\\silos_vlx_0.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>B8:D6:1A:60:94:1C</td>\n",
       "      <td>2025-07-15 16:17:27</td>\n",
       "      <td>335.0</td>\n",
       "      <td>data_drive\\LS5\\silos_vlx_0.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 mac                time    vlx                     source_file\n",
       "0  B8:D6:1A:60:94:1C 2025-07-15 11:47:13  330.0  data_drive\\LS5\\silos_vlx_0.csv\n",
       "1  B8:D6:1A:60:94:1C 2025-07-15 12:17:15  333.0  data_drive\\LS5\\silos_vlx_0.csv\n",
       "2  B8:D6:1A:60:94:1C 2025-07-15 12:47:17  339.0  data_drive\\LS5\\silos_vlx_0.csv\n",
       "3  B8:D6:1A:60:94:1C 2025-07-15 13:17:18  338.0  data_drive\\LS5\\silos_vlx_0.csv\n",
       "4  B8:D6:1A:60:94:1C 2025-07-15 13:47:20  342.0  data_drive\\LS5\\silos_vlx_0.csv\n",
       "5  B8:D6:1A:60:94:1C 2025-07-15 14:17:21  335.0  data_drive\\LS5\\silos_vlx_0.csv\n",
       "6  B8:D6:1A:60:94:1C 2025-07-15 14:47:23  335.0  data_drive\\LS5\\silos_vlx_0.csv\n",
       "7  B8:D6:1A:60:94:1C 2025-07-15 15:17:24  334.0  data_drive\\LS5\\silos_vlx_0.csv\n",
       "8  B8:D6:1A:60:94:1C 2025-07-15 15:47:26  331.0  data_drive\\LS5\\silos_vlx_0.csv\n",
       "9  B8:D6:1A:60:94:1C 2025-07-15 16:17:27  335.0  data_drive\\LS5\\silos_vlx_0.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "➡ Informe Markdown: D:\\ls_feed\\data_drive\\_eda\\ls5\\report.md\n",
      "\n",
      "=== EDA: ls6 ===\n",
      "Duplicados (filas completas): 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "mac",
         "rawType": "string",
         "type": "string"
        },
        {
         "name": "time",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "vlx",
         "rawType": "Float64",
         "type": "float"
        },
        {
         "name": "source_file",
         "rawType": "string",
         "type": "string"
        }
       ],
       "ref": "a53bfd88-f445-4c87-bb54-95240b2fb4f2",
       "rows": [
        [
         "0",
         "D8:13:2A:D2:36:B4",
         "2025-07-15 11:33:22",
         "374.0",
         "data_drive\\LS6\\silos_vlx_1.csv"
        ],
        [
         "1",
         "D8:13:2A:D2:36:B4",
         "2025-07-30 17:58:37",
         "373.0",
         "data_drive\\LS6\\silos_vlx_10.csv"
        ],
        [
         "2",
         "D8:13:2A:D2:36:B4",
         "2025-07-30 18:08:37",
         "381.0",
         "data_drive\\LS6\\silos_vlx_11.csv"
        ],
        [
         "3",
         "D8:13:2A:D2:36:B4",
         "2025-07-30 18:18:37",
         "391.0",
         "data_drive\\LS6\\silos_vlx_12.csv"
        ],
        [
         "4",
         "D8:13:2A:D2:36:B4",
         "2025-08-06 11:08:39",
         "236.0",
         "data_drive\\LS6\\silos_vlx_13.csv"
        ],
        [
         "5",
         "D8:13:2A:D2:36:B4",
         "2025-08-06 11:20:27",
         "230.0",
         "data_drive\\LS6\\silos_vlx_14.csv"
        ],
        [
         "6",
         "D8:13:2A:D2:36:B4",
         "2025-08-06 11:34:13",
         "229.0",
         "data_drive\\LS6\\silos_vlx_15.csv"
        ],
        [
         "7",
         "D8:13:2A:D2:36:B4",
         "2025-07-15 11:46:09",
         "371.0",
         "data_drive\\LS6\\silos_vlx_2.csv"
        ],
        [
         "8",
         "D8:13:2A:D2:36:B4",
         "2025-07-15 11:58:16",
         "378.0",
         "data_drive\\LS6\\silos_vlx_3.csv"
        ],
        [
         "9",
         "D8:13:2A:D2:36:B4",
         "2025-07-15 12:10:16",
         "379.0",
         "data_drive\\LS6\\silos_vlx_4.csv"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mac</th>\n",
       "      <th>time</th>\n",
       "      <th>vlx</th>\n",
       "      <th>source_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D8:13:2A:D2:36:B4</td>\n",
       "      <td>2025-07-15 11:33:22</td>\n",
       "      <td>374.0</td>\n",
       "      <td>data_drive\\LS6\\silos_vlx_1.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D8:13:2A:D2:36:B4</td>\n",
       "      <td>2025-07-30 17:58:37</td>\n",
       "      <td>373.0</td>\n",
       "      <td>data_drive\\LS6\\silos_vlx_10.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D8:13:2A:D2:36:B4</td>\n",
       "      <td>2025-07-30 18:08:37</td>\n",
       "      <td>381.0</td>\n",
       "      <td>data_drive\\LS6\\silos_vlx_11.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D8:13:2A:D2:36:B4</td>\n",
       "      <td>2025-07-30 18:18:37</td>\n",
       "      <td>391.0</td>\n",
       "      <td>data_drive\\LS6\\silos_vlx_12.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D8:13:2A:D2:36:B4</td>\n",
       "      <td>2025-08-06 11:08:39</td>\n",
       "      <td>236.0</td>\n",
       "      <td>data_drive\\LS6\\silos_vlx_13.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>D8:13:2A:D2:36:B4</td>\n",
       "      <td>2025-08-06 11:20:27</td>\n",
       "      <td>230.0</td>\n",
       "      <td>data_drive\\LS6\\silos_vlx_14.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>D8:13:2A:D2:36:B4</td>\n",
       "      <td>2025-08-06 11:34:13</td>\n",
       "      <td>229.0</td>\n",
       "      <td>data_drive\\LS6\\silos_vlx_15.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>D8:13:2A:D2:36:B4</td>\n",
       "      <td>2025-07-15 11:46:09</td>\n",
       "      <td>371.0</td>\n",
       "      <td>data_drive\\LS6\\silos_vlx_2.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>D8:13:2A:D2:36:B4</td>\n",
       "      <td>2025-07-15 11:58:16</td>\n",
       "      <td>378.0</td>\n",
       "      <td>data_drive\\LS6\\silos_vlx_3.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>D8:13:2A:D2:36:B4</td>\n",
       "      <td>2025-07-15 12:10:16</td>\n",
       "      <td>379.0</td>\n",
       "      <td>data_drive\\LS6\\silos_vlx_4.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 mac                time    vlx                      source_file\n",
       "0  D8:13:2A:D2:36:B4 2025-07-15 11:33:22  374.0   data_drive\\LS6\\silos_vlx_1.csv\n",
       "1  D8:13:2A:D2:36:B4 2025-07-30 17:58:37  373.0  data_drive\\LS6\\silos_vlx_10.csv\n",
       "2  D8:13:2A:D2:36:B4 2025-07-30 18:08:37  381.0  data_drive\\LS6\\silos_vlx_11.csv\n",
       "3  D8:13:2A:D2:36:B4 2025-07-30 18:18:37  391.0  data_drive\\LS6\\silos_vlx_12.csv\n",
       "4  D8:13:2A:D2:36:B4 2025-08-06 11:08:39  236.0  data_drive\\LS6\\silos_vlx_13.csv\n",
       "5  D8:13:2A:D2:36:B4 2025-08-06 11:20:27  230.0  data_drive\\LS6\\silos_vlx_14.csv\n",
       "6  D8:13:2A:D2:36:B4 2025-08-06 11:34:13  229.0  data_drive\\LS6\\silos_vlx_15.csv\n",
       "7  D8:13:2A:D2:36:B4 2025-07-15 11:46:09  371.0   data_drive\\LS6\\silos_vlx_2.csv\n",
       "8  D8:13:2A:D2:36:B4 2025-07-15 11:58:16  378.0   data_drive\\LS6\\silos_vlx_3.csv\n",
       "9  D8:13:2A:D2:36:B4 2025-07-15 12:10:16  379.0   data_drive\\LS6\\silos_vlx_4.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "➡ Informe Markdown: D:\\ls_feed\\data_drive\\_eda\\ls6\\report.md\n",
      "\n",
      "\n",
      "================ RESUMEN EJECUTIVO GLOBAL ================\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "shape",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "memory_human",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "n_numeric",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "n_categorical",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "n_datetime",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "corr_strong_pairs",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "report_path",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "941781db-f47d-46aa-9903-578b0ae46f6c",
       "rows": [
        [
         "0",
         "ls1",
         "{'rows': 1058, 'cols': 4}",
         "167.51 KB",
         "1",
         "2",
         "1",
         "[]",
         "D:\\ls_feed\\data_drive\\_eda\\ls1\\report.md"
        ],
        [
         "1",
         "ls2",
         "{'rows': 902, 'cols': 4}",
         "142.83 KB",
         "1",
         "2",
         "1",
         "[]",
         "D:\\ls_feed\\data_drive\\_eda\\ls2\\report.md"
        ],
        [
         "2",
         "ls3",
         "{'rows': 1056, 'cols': 4}",
         "167.19 KB",
         "1",
         "2",
         "1",
         "[]",
         "D:\\ls_feed\\data_drive\\_eda\\ls3\\report.md"
        ],
        [
         "3",
         "ls4",
         "{'rows': 1056, 'cols': 4}",
         "167.19 KB",
         "1",
         "2",
         "1",
         "[]",
         "D:\\ls_feed\\data_drive\\_eda\\ls4\\report.md"
        ],
        [
         "4",
         "ls5",
         "{'rows': 1058, 'cols': 4}",
         "167.51 KB",
         "1",
         "2",
         "1",
         "[]",
         "D:\\ls_feed\\data_drive\\_eda\\ls5\\report.md"
        ],
        [
         "5",
         "ls6",
         "{'rows': 15, 'cols': 4}",
         "2.51 KB",
         "1",
         "2",
         "1",
         "[]",
         "D:\\ls_feed\\data_drive\\_eda\\ls6\\report.md"
        ]
       ],
       "shape": {
        "columns": 8,
        "rows": 6
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>shape</th>\n",
       "      <th>memory_human</th>\n",
       "      <th>n_numeric</th>\n",
       "      <th>n_categorical</th>\n",
       "      <th>n_datetime</th>\n",
       "      <th>corr_strong_pairs</th>\n",
       "      <th>report_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ls1</td>\n",
       "      <td>{'rows': 1058, 'cols': 4}</td>\n",
       "      <td>167.51 KB</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>D:\\ls_feed\\data_drive\\_eda\\ls1\\report.md</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ls2</td>\n",
       "      <td>{'rows': 902, 'cols': 4}</td>\n",
       "      <td>142.83 KB</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>D:\\ls_feed\\data_drive\\_eda\\ls2\\report.md</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ls3</td>\n",
       "      <td>{'rows': 1056, 'cols': 4}</td>\n",
       "      <td>167.19 KB</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>D:\\ls_feed\\data_drive\\_eda\\ls3\\report.md</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ls4</td>\n",
       "      <td>{'rows': 1056, 'cols': 4}</td>\n",
       "      <td>167.19 KB</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>D:\\ls_feed\\data_drive\\_eda\\ls4\\report.md</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ls5</td>\n",
       "      <td>{'rows': 1058, 'cols': 4}</td>\n",
       "      <td>167.51 KB</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>D:\\ls_feed\\data_drive\\_eda\\ls5\\report.md</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ls6</td>\n",
       "      <td>{'rows': 15, 'cols': 4}</td>\n",
       "      <td>2.51 KB</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>D:\\ls_feed\\data_drive\\_eda\\ls6\\report.md</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  name                      shape memory_human  n_numeric  n_categorical  n_datetime corr_strong_pairs                               report_path\n",
       "0  ls1  {'rows': 1058, 'cols': 4}    167.51 KB          1              2           1                []  D:\\ls_feed\\data_drive\\_eda\\ls1\\report.md\n",
       "1  ls2   {'rows': 902, 'cols': 4}    142.83 KB          1              2           1                []  D:\\ls_feed\\data_drive\\_eda\\ls2\\report.md\n",
       "2  ls3  {'rows': 1056, 'cols': 4}    167.19 KB          1              2           1                []  D:\\ls_feed\\data_drive\\_eda\\ls3\\report.md\n",
       "3  ls4  {'rows': 1056, 'cols': 4}    167.19 KB          1              2           1                []  D:\\ls_feed\\data_drive\\_eda\\ls4\\report.md\n",
       "4  ls5  {'rows': 1058, 'cols': 4}    167.51 KB          1              2           1                []  D:\\ls_feed\\data_drive\\_eda\\ls5\\report.md\n",
       "5  ls6    {'rows': 15, 'cols': 4}      2.51 KB          1              2           1                []  D:\\ls_feed\\data_drive\\_eda\\ls6\\report.md"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resumen global guardado en: D:\\ls_feed\\data_drive\\_eda\\resumen_global.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nSalida:\\n- Variables disponibles en el notebook: df_ls1, df_ls2, ... (según existan .parquet).\\n- Carpeta con informes por dataset (Markdown + PNG + CSV): data_drive/_eda/<dataset>/\\n- Resumen ejecutivo consolidado: data_drive/_eda/resumen_global.csv\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %% EDA PROFESIONAL SOBRE TODOS LOS .parquet \"split\" (una celda lista para ejecutar)\n",
    "\n",
    "from __future__ import annotations\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "import textwrap\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --------------------------- CONFIGURACIÓN ---------------------------\n",
    "PARQUET_DIR = Path(\"data_drive/_parquet_export/split\")  # carpeta de entrada\n",
    "EDA_ROOT    = Path(\"data_drive/_eda\")                   # carpeta raíz de informes EDA\n",
    "MAX_BARS_PER_CAT = 10                                   # top categorías a graficar\n",
    "MAX_NUM_HISTS    = 6                                    # máximo de histogramas por dataset\n",
    "MAX_CAT_BARS     = 6                                    # máximo de barras de categorías por dataset\n",
    "MAX_TIME_SERIES  = 2                                    # máximo de series temporales a graficar\n",
    "SAMPLE_FOR_PLOTS = 250_000                              # muestreo para plots si el DF es muy grande\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 200)\n",
    "pd.set_option(\"display.width\", 2000)\n",
    "\n",
    "EDA_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# --------------------------- UTILIDADES ---------------------------\n",
    "\n",
    "def normalize_colnames(cols: List[str]) -> List[str]:\n",
    "    out = []\n",
    "    for c in cols:\n",
    "        c2 = (\n",
    "            str(c)\n",
    "            .strip()\n",
    "            .replace(\"\\n\", \" \")\n",
    "            .replace(\"\\r\", \" \")\n",
    "        )\n",
    "        c2 = \"_\".join(c2.split())  # colapsa espacios\n",
    "        out.append(c2)\n",
    "    # maneja duplicados conservando el orden\n",
    "    seen = {}\n",
    "    final = []\n",
    "    for c in out:\n",
    "        if c not in seen:\n",
    "            seen[c] = 0\n",
    "            final.append(c)\n",
    "        else:\n",
    "            seen[c] += 1\n",
    "            final.append(f\"{c}__dup{seen[c]}\")\n",
    "    return final\n",
    "\n",
    "def maybe_to_numeric(series: pd.Series) -> pd.Series:\n",
    "    if pd.api.types.is_numeric_dtype(series):\n",
    "        return series\n",
    "    # intenta parseo numérico si hay muchos caracteres numéricos\n",
    "    s = pd.to_numeric(series.astype(\"string\").str.replace(\",\", \".\", regex=False), errors=\"coerce\")\n",
    "    # convierte si al menos 85% de no-nulos sobreviven\n",
    "    non_null = series.notna().sum()\n",
    "    if non_null == 0:\n",
    "        return series\n",
    "    good = s.notna().sum() / non_null\n",
    "    return s if good >= 0.85 else series\n",
    "\n",
    "def maybe_to_datetime(series: pd.Series) -> pd.Series:\n",
    "    if pd.api.types.is_datetime64_any_dtype(series):\n",
    "        return series\n",
    "    # intento agresivo de parseo de fecha\n",
    "    s = pd.to_datetime(series, errors=\"coerce\", utc=False, infer_datetime_format=True)\n",
    "    non_null = series.notna().sum()\n",
    "    if non_null == 0:\n",
    "        return series\n",
    "    good = s.notna().sum() / non_null\n",
    "    return s if good >= 0.85 else series\n",
    "\n",
    "def infer_types(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df2 = df.copy()\n",
    "    # strip en strings\n",
    "    obj_cols = df2.select_dtypes(include=[\"object\", \"string\"]).columns\n",
    "    for c in obj_cols:\n",
    "        df2[c] = df2[c].astype(\"string\").str.strip()\n",
    "    # numéricos potenciales\n",
    "    for c in obj_cols:\n",
    "        df2[c] = maybe_to_numeric(df2[c])\n",
    "    # fechas potenciales (incluye columnas recién convertidas a string si falló numérico)\n",
    "    for c in df2.columns:\n",
    "        if df2[c].dtype == \"object\" or str(df2[c].dtype) == \"string\":\n",
    "            df2[c] = maybe_to_datetime(df2[c])\n",
    "    return df2\n",
    "\n",
    "def mem_info(df: pd.DataFrame) -> Tuple[int, str]:\n",
    "    b = df.memory_usage(deep=True).sum()\n",
    "    units = [\"B\",\"KB\",\"MB\",\"GB\",\"TB\"]\n",
    "    i = 0\n",
    "    val = float(b)\n",
    "    while val >= 1024 and i < len(units)-1:\n",
    "        val /= 1024.0\n",
    "        i += 1\n",
    "    return b, f\"{val:,.2f} {units[i]}\"\n",
    "\n",
    "def iqr_outlier_stats(s: pd.Series) -> Tuple[int, float, float, float]:\n",
    "    q1 = s.quantile(0.25)\n",
    "    q3 = s.quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    if not np.isfinite(iqr) or iqr == 0:\n",
    "        return 0, q1, q3, iqr\n",
    "    low = q1 - 1.5 * iqr\n",
    "    high = q3 + 1.5 * iqr\n",
    "    outliers = ((s < low) | (s > high)).sum()\n",
    "    return int(outliers), low, high, float(iqr)\n",
    "\n",
    "def safe_fig(path: Path):\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    plt.savefig(path, bbox_inches=\"tight\", dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "def plot_histograms(df: pd.DataFrame, name: str, out_dir: Path, max_plots: int = MAX_NUM_HISTS):\n",
    "    nums = df.select_dtypes(include=np.number).columns.tolist()\n",
    "    if not nums:\n",
    "        return []\n",
    "    cols = nums[:max_plots]\n",
    "    paths = []\n",
    "    # posible muestreo\n",
    "    data = df[cols]\n",
    "    if len(df) > SAMPLE_FOR_PLOTS:\n",
    "        data = data.sample(SAMPLE_FOR_PLOTS, random_state=42)\n",
    "    for c in cols:\n",
    "        plt.figure()\n",
    "        data[c].dropna().plot(kind=\"hist\", bins=50, title=f\"{name} - Histograma: {c}\")\n",
    "        p = out_dir / f\"hist_{c}.png\"\n",
    "        safe_fig(p)\n",
    "        paths.append(p)\n",
    "    return paths\n",
    "\n",
    "def plot_top_categories(df: pd.DataFrame, name: str, out_dir: Path, max_plots: int = MAX_CAT_BARS, k:int = MAX_BARS_PER_CAT):\n",
    "    cats = df.select_dtypes(include=[\"object\",\"string\",\"category\"]).columns.tolist()\n",
    "    if not cats:\n",
    "        return []\n",
    "    cols = cats[:max_plots]\n",
    "    paths = []\n",
    "    for c in cols:\n",
    "        vc = df[c].value_counts(dropna=False).head(k)\n",
    "        plt.figure(figsize=(8,4))\n",
    "        vc.plot(kind=\"bar\", title=f\"{name} - Top {k} categorías: {c}\", rot=45)\n",
    "        p = out_dir / f\"bar_{c}.png\"\n",
    "        safe_fig(p)\n",
    "        paths.append(p)\n",
    "    return paths\n",
    "\n",
    "def plot_time_series(df: pd.DataFrame, name: str, out_dir: Path, max_plots: int = MAX_TIME_SERIES):\n",
    "    dt_cols = df.select_dtypes(include=[\"datetime64[ns]\", \"datetime64[ns, UTC]\"]).columns.tolist()\n",
    "    paths = []\n",
    "    if not dt_cols:\n",
    "        return paths\n",
    "    cols = dt_cols[:max_plots]\n",
    "    for c in cols:\n",
    "        s = df[c].dropna().sort_values()\n",
    "        if s.empty:\n",
    "            continue\n",
    "        # agrega por día\n",
    "        counts = s.dt.floor(\"D\").value_counts().sort_index()\n",
    "        plt.figure(figsize=(9,4))\n",
    "        counts.plot(title=f\"{name} - Frecuencia diaria: {c}\")\n",
    "        p = out_dir / f\"ts_daily_{c}.png\"\n",
    "        safe_fig(p)\n",
    "        paths.append(p)\n",
    "    return paths\n",
    "\n",
    "def top_correlations(df: pd.DataFrame, thr: float = 0.7, topk: int = 20) -> List[Tuple[str, str, float]]:\n",
    "    nums = df.select_dtypes(include=np.number)\n",
    "    if nums.shape[1] < 2:\n",
    "        return []\n",
    "    corr = nums.corr(numeric_only=True)\n",
    "    pairs = []\n",
    "    cols = corr.columns.tolist()\n",
    "    for i in range(len(cols)):\n",
    "        for j in range(i+1, len(cols)):\n",
    "            v = corr.iloc[i, j]\n",
    "            if pd.notna(v):\n",
    "                pairs.append((cols[i], cols[j], float(v)))\n",
    "    pairs = sorted(pairs, key=lambda x: abs(x[2]), reverse=True)\n",
    "    if thr is not None:\n",
    "        pairs = [p for p in pairs if abs(p[2]) >= thr]\n",
    "    return pairs[:topk]\n",
    "\n",
    "def df_quick_profile(df: pd.DataFrame) -> Dict:\n",
    "    n_rows, n_cols = df.shape\n",
    "    dtypes = df.dtypes.astype(str).to_dict()\n",
    "    nulls = df.isna().sum().to_dict()\n",
    "    nulls_pct = {k: (v / n_rows * 100.0) if n_rows else 0.0 for k, v in nulls.items()}\n",
    "    uniques = df.nunique(dropna=False).to_dict()\n",
    "    zeros_pct = {}\n",
    "    for c in df.select_dtypes(include=np.number).columns:\n",
    "        zeros = (df[c] == 0).sum()\n",
    "        zeros_pct[c] = (zeros / n_rows * 100.0) if n_rows else 0.0\n",
    "    mem_bytes, mem_hr = mem_info(df)\n",
    "    return {\n",
    "        \"shape\": {\"rows\": int(n_rows), \"cols\": int(n_cols)},\n",
    "        \"memory\": {\"bytes\": int(mem_bytes), \"human_readable\": mem_hr},\n",
    "        \"dtypes\": dtypes,\n",
    "        \"nulls\": nulls,\n",
    "        \"nulls_pct\": {k: round(v, 3) for k, v in nulls_pct.items()},\n",
    "        \"uniques\": uniques,\n",
    "        \"zeros_pct_numeric\": {k: round(v, 3) for k, v in zeros_pct.items()},\n",
    "    }\n",
    "\n",
    "def describe_numeric_plus(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    nums = df.select_dtypes(include=np.number)\n",
    "    if nums.empty:\n",
    "        return pd.DataFrame()\n",
    "    desc = nums.describe().T\n",
    "    desc[\"skew\"] = nums.skew(numeric_only=True)\n",
    "    desc[\"kurtosis\"] = nums.kurt(numeric_only=True)\n",
    "    # outliers IQR\n",
    "    outs = []\n",
    "    for c in nums.columns:\n",
    "        s = nums[c].dropna()\n",
    "        count, low, high, iqr = iqr_outlier_stats(s)\n",
    "        pct = (count / len(nums)) * 100 if len(nums) else 0.0\n",
    "        outs.append((c, count, pct, low, high, iqr))\n",
    "    outs_df = pd.DataFrame(outs, columns=[\"col\",\"outliers_count\",\"outliers_pct\",\"low_fence\",\"high_fence\",\"iqr\"]).set_index(\"col\")\n",
    "    return desc.join(outs_df, how=\"left\")\n",
    "\n",
    "def write_markdown_report(\n",
    "    name: str,\n",
    "    profile: Dict,\n",
    "    num_desc: pd.DataFrame,\n",
    "    corr_pairs: List[Tuple[str,str,float]],\n",
    "    fig_paths: List[Path],\n",
    "    out_dir: Path\n",
    ") -> None:\n",
    "    md = []\n",
    "    md.append(f\"# EDA - {name}\\n\")\n",
    "    md.append(\"## Resumen\")\n",
    "    md.append(f\"- **Filas**: {profile['shape']['rows']:,}\")\n",
    "    md.append(f\"- **Columnas**: {profile['shape']['cols']:,}\")\n",
    "    md.append(f\"- **Memoria**: {profile['memory']['human_readable']} ({profile['memory']['bytes']:,} bytes)\")\n",
    "    # tipos\n",
    "    type_counts = pd.Series(profile[\"dtypes\"]).value_counts().to_dict()\n",
    "    md.append(f\"- **Tipos de datos**: {', '.join([f'{k}: {v}' for k,v in type_counts.items()])}\")\n",
    "    # nulos top\n",
    "    nulls_pct = pd.Series(profile[\"nulls_pct\"]).sort_values(ascending=False).head(10)\n",
    "    if len(nulls_pct) > 0:\n",
    "        md.append(\"\\n## Top columnas por % de nulos\")\n",
    "        md.append(nulls_pct.to_frame(\"nulls_pct\").to_markdown())\n",
    "    # únicos top\n",
    "    uniques = pd.Series(profile[\"uniques\"]).sort_values(ascending=False).head(10)\n",
    "    md.append(\"\\n## Top columnas por cardinalidad\")\n",
    "    md.append(uniques.to_frame(\"unique_values\").to_markdown())\n",
    "    # numéricos\n",
    "    if not num_desc.empty:\n",
    "        md.append(\"\\n## Resumen numérico extendido\")\n",
    "        md.append(num_desc.round(4).to_markdown())\n",
    "    # correlaciones\n",
    "    if corr_pairs:\n",
    "        md.append(\"\\n## Correlaciones fuertes (|r| ≥ 0.70)\")\n",
    "        corr_df = pd.DataFrame(corr_pairs, columns=[\"col1\",\"col2\",\"pearson_r\"])\n",
    "        md.append(corr_df.to_markdown(index=False))\n",
    "    # figuras\n",
    "    if fig_paths:\n",
    "        md.append(\"\\n## Gráficas\")\n",
    "        for p in fig_paths:\n",
    "            rel = p.name\n",
    "            md.append(f\"![{rel}]({rel})\")\n",
    "    # guarda\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    (out_dir / \"report.md\").write_text(\"\\n\\n\".join(md), encoding=\"utf-8\")\n",
    "\n",
    "def eda_for_dataframe(df: pd.DataFrame, dataset_name: str, base_out_dir: Path) -> Dict:\n",
    "    \"\"\"Ejecuta EDA completo, guarda artefactos y devuelve un dict resumen.\"\"\"\n",
    "    out_dir = base_out_dir / dataset_name\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Perfil básico\n",
    "    profile = df_quick_profile(df)\n",
    "\n",
    "    # Descripción numérica extendida\n",
    "    num_desc = describe_numeric_plus(df)\n",
    "\n",
    "    # Correlaciones fuertes\n",
    "    corr_pairs = top_correlations(df, thr=0.70, topk=30)\n",
    "\n",
    "    # Gráficas\n",
    "    fig_paths = []\n",
    "    fig_paths += plot_histograms(df, dataset_name, out_dir)\n",
    "    fig_paths += plot_top_categories(df, dataset_name, out_dir)\n",
    "    fig_paths += plot_time_series(df, dataset_name, out_dir)\n",
    "\n",
    "    # Guarda perfil JSON + CSVs de apoyo\n",
    "    (out_dir / \"profile.json\").write_text(json.dumps(profile, indent=2, ensure_ascii=False), encoding=\"utf-8\")\n",
    "    if not num_desc.empty:\n",
    "        num_desc.to_csv(out_dir / \"numeric_summary.csv\", index=True)\n",
    "\n",
    "    # Reporte Markdown\n",
    "    write_markdown_report(dataset_name, profile, num_desc, corr_pairs, fig_paths, out_dir)\n",
    "\n",
    "    # Devuelve resumen ejecutivo\n",
    "    return {\n",
    "        \"name\": dataset_name,\n",
    "        \"shape\": profile[\"shape\"],\n",
    "        \"memory_human\": profile[\"memory\"][\"human_readable\"],\n",
    "        \"n_numeric\": int(df.select_dtypes(include=np.number).shape[1]),\n",
    "        \"n_categorical\": int(df.select_dtypes(include=['object','string','category']).shape[1]),\n",
    "        \"n_datetime\": int(df.select_dtypes(include=['datetime64[ns]','datetime64[ns, UTC]']).shape[1]),\n",
    "        \"corr_strong_pairs\": corr_pairs[:5],\n",
    "        \"report_path\": str((out_dir / \"report.md\").resolve()),\n",
    "    }\n",
    "\n",
    "# --------------------------- PIPELINE PRINCIPAL ---------------------------\n",
    "\n",
    "# 1) Descubre .parquet\n",
    "parquets = sorted(PARQUET_DIR.glob(\"*.parquet\"))\n",
    "if not parquets:\n",
    "    raise SystemExit(f\"No se encontraron .parquet en {PARQUET_DIR.resolve()}\")\n",
    "\n",
    "# 2) Carga y tipificación\n",
    "dfs: Dict[str, pd.DataFrame] = {}\n",
    "for p in parquets:\n",
    "    name = p.stem  # p.ej., \"ls1\"\n",
    "    df = pd.read_parquet(p)\n",
    "    # normaliza nombres de columnas\n",
    "    df.columns = normalize_colnames(df.columns.tolist())\n",
    "    # inferencia de tipos\n",
    "    df = infer_types(df)\n",
    "    # expone como variable global df_<name> si es un nombre válido\n",
    "    var_name = f\"df_{name.lower()}\"\n",
    "    globals()[var_name] = df\n",
    "    dfs[name.lower()] = df\n",
    "    print(f\"Cargado {p.name} -> variable: {var_name} | shape={df.shape}\")\n",
    "\n",
    "# 3) EDA por DataFrame\n",
    "executive_summary = []\n",
    "for name, df in dfs.items():\n",
    "    print(f\"\\n=== EDA: {name} ===\")\n",
    "    # duplicados de filas completas\n",
    "    dup_count = df.duplicated().sum()\n",
    "    print(f\"Duplicados (filas completas): {dup_count:,}\")\n",
    "    # vista rápida\n",
    "    display(df.head(10))\n",
    "\n",
    "    summary = eda_for_dataframe(df, dataset_name=name, base_out_dir=EDA_ROOT)\n",
    "    executive_summary.append(summary)\n",
    "    print(f\"➡ Informe Markdown: {summary['report_path']}\")\n",
    "\n",
    "# 4) Resumen ejecutivo global\n",
    "print(\"\\n\\n================ RESUMEN EJECUTIVO GLOBAL ================\")\n",
    "summary_df = pd.DataFrame(executive_summary)\n",
    "display(summary_df)\n",
    "\n",
    "# 5) Guardado del resumen global\n",
    "summary_path = (EDA_ROOT / \"resumen_global.csv\")\n",
    "summary_df.to_csv(summary_path, index=False)\n",
    "print(f\"Resumen global guardado en: {summary_path.resolve()}\")\n",
    "\n",
    "\"\"\"\n",
    "Salida:\n",
    "- Variables disponibles en el notebook: df_ls1, df_ls2, ... (según existan .parquet).\n",
    "- Carpeta con informes por dataset (Markdown + PNG + CSV): data_drive/_eda/<dataset>/\n",
    "- Resumen ejecutivo consolidado: data_drive/_eda/resumen_global.csv\n",
    "\"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
